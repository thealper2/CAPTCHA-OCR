{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "from tensorflow.keras.backend import ctc_batch_cost, ctc_decode\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/kaggle/input/captcha-version-2-images/samples/samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for file in tqdm.tqdm(os.listdir(root_dir)):\n",
    "    filepath = os.path.join(root_dir, file)\n",
    "    label = filepath.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    image_paths.append(filepath)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.DataFrame({\"image_path\": image_paths, \"label\": labels})\n",
    "images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = set(char for label in labels for char in label)\n",
    "print(\"Characters:\\n\", characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num = layers.StringLookup(\n",
    "    vocabulary = list(characters),\n",
    "    num_oov_indices = 0,\n",
    "    mask_token = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"char\": char_to_num.get_vocabulary(),\n",
    "              \"num\": np.arange(1, len(char_to_num.get_vocabulary())+1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary = char_to_num.get_vocabulary(),\n",
    "    mask_token = None,\n",
    "    invert = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_single_sample(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [50, 200])\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(X, y):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for img_path, label in zip(X, y):\n",
    "        img, lbl = encode_single_sample(img_path, label)\n",
    "        images.append(img.numpy())\n",
    "        labels.append(lbl.numpy())\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(image_paths), np.array(labels), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed, y_train_processed = process_dataset(X_train, y_train)\n",
    "X_test_processed, y_test_processed = process_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_input = {\"Input\": X_train_processed, \"Label\": y_train_processed}\n",
    "X_test_input = {\"Input\": X_test_processed, \"Label\": y_test_processed}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_df(df: pd.DataFrame):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(10, 5))\n",
    "\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        if i < len(df):\n",
    "            a = np.random.randint(1, len(df), 1)[0]\n",
    "            img_path = df.loc[a][['image_path']].values[0]\n",
    "            label = df.loc[a][[\"label\"]].values[0]\n",
    "            \n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            ax.imshow(image)\n",
    "            ax.set_title(f\"CAPTCHA: {label}\")\n",
    "            ax.axis('off')\n",
    "            \n",
    "        else:\n",
    "            ax.axis('off')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_df(images_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_length = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_length, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_length, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(200, 50, 1), name=\"Input\", dtype=\"float32\")\n",
    "label_layer = layers.Input(shape=(None,), name=\"Label\", dtype=\"float32\")\n",
    "\n",
    "conv2_1 = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(input_layer)\n",
    "max2_1 = layers.MaxPooling2D(strides=(2, 2))(conv2_1)\n",
    "\n",
    "conv2_2 = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(max2_1)\n",
    "max2_2 = layers.MaxPooling2D(strides=(2, 2))(conv2_2)\n",
    "\n",
    "reshape_layer = layers.Reshape(target_shape=((200 // 4), (50 // 4) * 64))(max2_2)\n",
    "dense_1 = layers.Dense(units=64, activation=\"relu\")(reshape_layer)\n",
    "drop_1 = layers.Dropout((0.2))(dense_1)\n",
    "\n",
    "bilstm_1 = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(drop_1)\n",
    "bilstm_2 = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(bilstm_1)\n",
    "\n",
    "output_layer = layers.Dense(len(characters) + 1, activation=\"softmax\", name=\"Output\")(bilstm_2)\n",
    "\n",
    "output = CTCLayer(name=\"ctc_loss\")(label_layer, output_layer)\n",
    "\n",
    "model = models.Model(inputs=[input_layer, label_layer], outputs=output, name=\"OCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_layer_names=True, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_input,\n",
    "    y_train_processed,\n",
    "    validation_data=(X_test_input, y_test_processed),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    #callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"valid\"])\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test_input)\n",
    "input_length = np.ones(preds.shape[0]) * preds.shape[1]\n",
    "results = ctc_decode(preds, input_length=input_length, greedy=True)[0][0][:, :5]\n",
    "pred_texts = []\n",
    "for result in results:\n",
    "    res = tf.strings.reduce_join(num_to_char(result+1)).numpy().decode(\"utf-8\")\n",
    "    pred_texts.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    \"image_path\": X_test,\n",
    "    \"label\": y_test,\n",
    "    \"pred\": pred_texts\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(df: pd.DataFrame):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(10, 5))\n",
    "\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        if i < len(df):\n",
    "            a = np.random.randint(1, len(df), 1)[0]\n",
    "            img_path = df.loc[a][['image_path']].values[0]\n",
    "            label = df.loc[a][[\"label\"]].values[0]\n",
    "            pred = df.loc[a][[\"pred\"]].values[0]\n",
    "            \n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            ax.imshow(image)\n",
    "            ax.set_title(f\"True: {label}\\nPred: {pred}\")\n",
    "            ax.axis('off')\n",
    "            \n",
    "        else:\n",
    "            ax.axis('off')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
